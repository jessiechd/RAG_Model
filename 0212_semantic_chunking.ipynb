{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMMydYWy/ptg8SgIbIfQz0v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessiechd/RAG_Model/blob/main/0212_semantic_chunking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers rouge  --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt1Xf4PeBYOU",
        "outputId": "11d91613-f584-40da-f2c6-f3228707ffdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Chunking: Testing with documents\n",
        "- variations in minimum sentences per chunk and overlaps\n",
        "- coherence score for evaluation"
      ],
      "metadata": {
        "id": "dJUK_evyIGWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import rouge\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "hoxlVlHFIWwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextChunker2:\n",
        "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v1'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def process_file(self, file_path, dynamic_window=True, min_chunk_size=3, overlap=1, num_clusters=5):\n",
        "        # Step 1: Load and encode text\n",
        "        sentences = self._load_text(file_path)\n",
        "        contextualized = self._add_dynamic_context(sentences) if dynamic_window else self._add_fixed_context(sentences)\n",
        "        embeddings = self.model.encode(contextualized)\n",
        "\n",
        "        # Step 2: Compute cosine distances between consecutive embeddings\n",
        "        distances = self._calculate_distances(embeddings)\n",
        "\n",
        "        # Step 3: Identify breakpoints based on semantic gaps\n",
        "        breakpoints = self._identify_breakpoints(distances, num_clusters)\n",
        "\n",
        "        # Step 4: Create initial chunks with overlap\n",
        "        initial_chunks = self._create_chunks(sentences, breakpoints, overlap)\n",
        "\n",
        "        # Step 5: Merge small chunks for better coherence\n",
        "        if min_chunk_size > 1:  # Ensure chunks are not too small\n",
        "            chunk_embeddings = self.model.encode(initial_chunks)\n",
        "            final_chunks = self._merge_small_chunks(initial_chunks, chunk_embeddings, min_chunk_size)\n",
        "        else:\n",
        "            final_chunks = initial_chunks  # Skip merging if min_chunk_size is 1\n",
        "\n",
        "        return final_chunks\n",
        "\n",
        "\n",
        "    def _load_text(self, file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "        return sent_tokenize(text)\n",
        "\n",
        "    def _add_fixed_context(self, sentences, window_size=1):\n",
        "        return [' '.join(sentences[max(0, i-window_size): min(len(sentences), i+window_size+1)]) for i in range(len(sentences))]\n",
        "\n",
        "    def _add_dynamic_context(self, sentences):\n",
        "        contextualized = []\n",
        "        embeddings = self.model.encode(sentences)\n",
        "        for i in range(len(sentences)):\n",
        "            similarities = cosine_similarity([embeddings[i]], embeddings)[0]\n",
        "            closest_indices = np.argsort(-similarities)[:3]  # Select 2 most relevant neighbors\n",
        "            context = ' '.join(sentences[j] for j in sorted(closest_indices))\n",
        "            contextualized.append(context)\n",
        "        return contextualized\n",
        "\n",
        "    def _identify_breakpoints(self, distances, threshold_percentile=90):\n",
        "        \"\"\"Find breakpoints where semantic distance is high.\"\"\"\n",
        "        threshold = np.percentile(distances, threshold_percentile)  # Dynamic threshold\n",
        "        return [i for i, dist in enumerate(distances) if dist > threshold]\n",
        "\n",
        "    # def _identify_breakpoints(self, distances, num_clusters=3):\n",
        "    #     distances = np.array(distances).reshape(-1, 1)  # Reshape for clustering\n",
        "    #     kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    #     kmeans.fit(distances)\n",
        "    #     labels = kmeans.labels_\n",
        "\n",
        "    #     # Find cluster with highest distance values\n",
        "    #     breakpoint_cluster = np.argmax(kmeans.cluster_centers_)\n",
        "    #     return [i for i, label in enumerate(labels) if label == breakpoint_cluster]\n",
        "\n",
        "    def _create_chunks(self, sentences, breakpoints, overlap=1):\n",
        "        chunks = []\n",
        "        start_idx = 0\n",
        "\n",
        "        for breakpoint in breakpoints:\n",
        "            end_idx = breakpoint + 1\n",
        "            chunk = ' '.join(sentences[max(0, start_idx - overlap):end_idx])\n",
        "            chunks.append(chunk)\n",
        "            start_idx = end_idx\n",
        "\n",
        "        final_chunk = ' '.join(sentences[max(0, start_idx - overlap):])\n",
        "        chunks.append(final_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def _merge_small_chunks(self, chunks, embeddings, min_size):\n",
        "        final_chunks, merged_embeddings = [chunks[0]], [embeddings[0]]\n",
        "        for i in range(1, len(chunks) - 1):\n",
        "            if len(chunks[i].split('. ')) < min_size:\n",
        "                prev_sim = cosine_similarity([embeddings[i]], [merged_embeddings[-1]])[0][0]\n",
        "                next_sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "                if prev_sim > next_sim:\n",
        "                    final_chunks[-1] += ' ' + chunks[i]\n",
        "                    merged_embeddings[-1] = (merged_embeddings[-1] + embeddings[i]) / 2\n",
        "                else:\n",
        "                    chunks[i + 1] = chunks[i] + ' ' + chunks[i + 1]\n",
        "                    embeddings[i + 1] = (embeddings[i] + embeddings[i + 1]) / 2\n",
        "            else:\n",
        "                final_chunks.append(chunks[i])\n",
        "                merged_embeddings.append(embeddings[i])\n",
        "        final_chunks.append(chunks[-1])\n",
        "        return final_chunks\n",
        "\n",
        "    def _calculate_distances(self, embeddings):\n",
        "      \"\"\"Calculate cosine distances between consecutive embeddings.\"\"\"\n",
        "      distances = []\n",
        "      for i in range(len(embeddings) - 1):\n",
        "          similarity = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "          distance = 1 - similarity  # Distance = 1 - similarity\n",
        "          distances.append(distance)\n",
        "      return distances\n",
        "\n",
        "    def evaluate_coherence(self, chunks):\n",
        "        coherence_scores = []\n",
        "        embeddings = self.model.encode(chunks)\n",
        "        for i in range(len(embeddings) - 1):\n",
        "            score = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "            coherence_scores.append(score)\n",
        "        return np.mean(coherence_scores)\n",
        "\n",
        "    def evaluate_rouge(self, original_text, chunks):\n",
        "        rouge_evaluator = rouge.Rouge()\n",
        "        scores = [rouge_evaluator.get_scores(chunk, original_text)[0]['rouge-1']['f'] for chunk in chunks]\n",
        "        return np.mean(scores)\n",
        "\n",
        "    def evaluate_qa_performance(self, chunks, test_questions):\n",
        "        chunk_embeddings = self.model.encode(chunks)\n",
        "\n",
        "        def retrieve_best_chunk(query):\n",
        "            from sentence_transformers import CrossEncoder\n",
        "            reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "            query_embedding = self.model.encode([query])\n",
        "            similarities = cosine_similarity(query_embedding, chunk_embeddings)[0]\n",
        "            top_n = np.argsort(similarities)[-3:]\n",
        "            rerank_scores = reranker.predict([[query, chunks[i]] for i in top_n])\n",
        "            return chunks[top_n[np.argmax(rerank_scores)]]\n",
        "\n",
        "        correct = 0\n",
        "        for question, expected_answer in test_questions:\n",
        "            retrieved_chunk = retrieve_best_chunk(question)\n",
        "            if expected_answer in retrieved_chunk:\n",
        "                correct += 1\n",
        "\n",
        "        return correct / len(test_questions)\n"
      ],
      "metadata": {
        "id": "PSb1Qq2vIIn0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "chunker2 = TextChunker2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvHGyaQ8pHIc",
        "outputId": "3ebdb8c3-cce7-4c2f-984a-29e3afdaaa91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #1: \"17.pdf\""
      ],
      "metadata": {
        "id": "KuG56cs15Fmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/17_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Where does the family medicine training take place?\", \"Africa\")\n",
        "]"
      ],
      "metadata": {
        "id": "p9H7ywMINxGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunker_test(mcs, ovl):\n",
        "    chunks2 = chunker2.process_file(\n",
        "        file_path,\n",
        "        dynamic_window=True,\n",
        "        min_chunk_size=mcs,\n",
        "        overlap=ovl,\n",
        "        num_clusters=3)\n",
        "\n",
        "    print(f\"Using min_chunk_size={mcs}, overlap={ovl}\")\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Successfully split text into {len(chunks2)} chunks\")\n",
        "\n",
        "    # for i in range(len(chunks2)):\n",
        "    #     print(f\"Chunk {i+1}: {len(chunks2[i].split('. '))} sentences\")\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    coherence_score = chunker2.evaluate_coherence(chunks2)\n",
        "    # rouge_score = chunker2.evaluate_rouge(text, chunks2)  # Fixed variable\n",
        "    qa_accuracy = chunker2.evaluate_qa_performance(chunks2, test_questions)  # Removed retrieval_system\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(f\"Coherence Score: {coherence_score:.4f}\")\n",
        "    # print(f\"ROUGE Score: {rouge_score:.4f}\")\n",
        "    print(f\"QA Accuracy: {qa_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "WtlFKDW2CQ6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHxpBpGGon1Q",
        "outputId": "a7623b34-3829-4662-e006-1f43c9e5fda0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 102 chunks\n",
            "Coherence Score: 0.5870\n",
            "ROUGE Score: 0.0593\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMtq45_0Cc_2",
        "outputId": "f3fc71d2-7a04-4c48-b181-792a8bfc2000"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 80 chunks\n",
            "Coherence Score: 0.6504\n",
            "ROUGE Score: 0.0835\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwA4jFXZCgrC",
        "outputId": "0fab1a66-7ff4-4141-980f-4e8714822b53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 58 chunks\n",
            "Coherence Score: 0.7273\n",
            "ROUGE Score: 0.1122\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43G0V091CiXp",
        "outputId": "245b2b1a-a901-4176-db46-cfeac4520355"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 52 chunks\n",
            "Coherence Score: 0.7788\n",
            "ROUGE Score: 0.1448\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXS7OsmhCkUQ",
        "outputId": "23e68c48-5635-4b25-b729-292f619a3673"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 51 chunks\n",
            "Coherence Score: 0.7969\n",
            "ROUGE Score: 0.1585\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #2: \"PDF1.pdf\""
      ],
      "metadata": {
        "id": "OXp3RsPIo810"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/PDF1_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Which industry sector does the study focus on?\", \"semiconductor\"),\n",
        "    (\"WWhat machine learning subfield is sentiment analysis a part of?\", \"NLP\")\n",
        "]"
      ],
      "metadata": {
        "id": "zKxz5AarAYiw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52721854-a262-4266-b189-829603d696da",
        "id": "tauoiV-7Cpee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 202 chunks\n",
            "Coherence Score: 0.5717\n",
            "ROUGE Score: 0.0371\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2WzF5VCpee",
        "outputId": "d6a3baf2-f728-4f7f-8a9f-33a8213ac05a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 174 chunks\n",
            "Coherence Score: 0.6755\n",
            "ROUGE Score: 0.0497\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfo8aPQ1Cpef",
        "outputId": "edee4c17-502b-4efa-bd59-0fd7f919b7f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 120 chunks\n",
            "Coherence Score: 0.6795\n",
            "ROUGE Score: 0.0679\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl2_C9kFCpef",
        "outputId": "239548f8-83ec-4125-e911-0edbc50322ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 109 chunks\n",
            "Coherence Score: 0.7519\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baSa1lvACpef",
        "outputId": "a0a94a4d-4fe8-4459-a691-48ca781f6523"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 105 chunks\n",
            "Coherence Score: 0.7688\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #3: \"2024_11_05 - Ferrari Q3 2024 Results Press Release.pdf\""
      ],
      "metadata": {
        "id": "K5_e2rQADX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/2024_11_05 - Ferrari Q3 2024 Results Press Release_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Where is Ferrari's factory located?\", \"Maranello\"),\n",
        "    (\"What is the brand this document mentioned?\", \"Ferrari\")\n",
        "]"
      ],
      "metadata": {
        "id": "CLzpdaE_DX3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f3c045-36c6-46c7-99ad-e8fd99bc4da2",
        "id": "kPr4DIC7DX3S"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 53 chunks\n",
            "Coherence Score: 0.5453\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PjB_YqmDX3T",
        "outputId": "bad202ce-c27c-489d-ad0b-d676dbe9b1c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 42 chunks\n",
            "Coherence Score: 0.5961\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHaulj-DDX3T",
        "outputId": "7b1d104e-9281-47ea-f83b-8203bdc40753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 32 chunks\n",
            "Coherence Score: 0.6668\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JVV11xSDX3T",
        "outputId": "3bd3fa81-94c2-498c-af51-5b6370150383"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 24 chunks\n",
            "Coherence Score: 0.6642\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCcU474SDX3U",
        "outputId": "6dc5e68e-3ff7-488b-de2d-7ea6a9e15e3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 26 chunks\n",
            "Coherence Score: 0.7087\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #4: \"ai-in-america-oai-economic-blueprint-20250113.pdf\""
      ],
      "metadata": {
        "id": "9qxvV-voGCiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/ai-in-america-oai-economic-blueprint-20250113_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is OpenAI's mission?\", \"benefits everyone\"),\n",
        "    (\"How many people are currently using OpenAI's tools?\", \"300 million\")\n",
        "]"
      ],
      "metadata": {
        "id": "gyLRO4jtGCiX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpF-aUrkGCiX",
        "outputId": "8de6ac34-1822-4bc8-a384-8d1c45d7a0af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 74 chunks\n",
            "Coherence Score: 0.5756\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlXsvEhpGCiY",
        "outputId": "653f178c-15ae-428a-e6a6-52b53566c574"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 68 chunks\n",
            "Coherence Score: 0.6318\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOoTTXeYGCiY",
        "outputId": "7ad15bf7-ada8-4270-9479-296329009426"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 42 chunks\n",
            "Coherence Score: 0.6412\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIJlPXU1GCiY",
        "outputId": "5fbe79fb-0a38-4a9f-9de4-7b7c4eee00a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 46 chunks\n",
            "Coherence Score: 0.7270\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZhnoAJHGCiY",
        "outputId": "f97c4402-9b6e-4687-ced5-55a4552abd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 39 chunks\n",
            "Coherence Score: 0.7016\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #5: \"creatingsystem.pdf\""
      ],
      "metadata": {
        "id": "r7sI95dUK1Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/creatingsystem_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is a water system operations and maintenance manual?\", \"comprehensive 'how-to' guidance document\"),\n",
        "    (\"Why is the manual necessary?\", \"detailed resource\")\n",
        "]"
      ],
      "metadata": {
        "id": "rUaRSQbQK1Cg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145ea7c0-74b1-4607-d978-5a3a8cc54bd8",
        "id": "MqeLsvicK1Cg"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 6 chunks\n",
            "Coherence Score: 0.6066\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6thLzuZKK1Cg",
        "outputId": "8e8b7be9-e58b-42ec-a3d4-4aeeabf5baa5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 5 chunks\n",
            "Coherence Score: 0.6121\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1eaa6vwK1Ch",
        "outputId": "b0be1bc9-52d7-448d-98f3-8c01aed2926e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 3 chunks\n",
            "Coherence Score: 0.3867\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiq9EZAK1Ch",
        "outputId": "861afbcb-d61c-4b96-91e6-cb5bfbab899a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 4 chunks\n",
            "Coherence Score: 0.5249\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Sc2naqK1Ch",
        "outputId": "747b306b-9dbc-46a2-8b1f-54f867996b3e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 3 chunks\n",
            "Coherence Score: 0.3822\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #6: \"2014-monarch-plus-service-manual.pdf\""
      ],
      "metadata": {
        "id": "pJBUNjNjqhG6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/2014-monarch-plus-service-manual.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is the company name of these products?\", \"Monarch\"),\n",
        "    (\"What are the tools needed for service?\", \"Safety glasses\")\n",
        "]"
      ],
      "metadata": {
        "id": "FORhfc-WqhG7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 246,
          "referenced_widgets": [
            "4b9ad0e620594c61802da9b580f167c8",
            "0e380431e9694088be2b75f3c270c259",
            "184eebf3fe1946adb094276fe933994f",
            "042e6aebfce3461191ccc1d0bae54ff2",
            "3f7f7581dd2f422a95e24f71b7002cea",
            "0334ec36f9cb4891a66109263fa804da",
            "3d03bb4b96a74061a5b41221e5d9aed7",
            "99bb0e27f94b4a4b8c6b0855ed579a0f",
            "caf5a12933574738906ba48690a8884f",
            "540057be6e0c478da0c22c52d8e21542",
            "522be3012b8545ed8acce150ecdc1590",
            "d062d9b691294f1d8d17a8e0848cae24",
            "a2e7f2e5f7764319b0f33de6bfce3457",
            "e970d8f8b944404ba7fa1a036a82ad1b",
            "61f33e7766d84f13aec741afc77c8b71",
            "51623d13aa54443fa9227516c0822a62",
            "fbeca8a7d46f4322be91f2700861b42b",
            "740c84fc00f340a6ae695e50babbc8fb",
            "7e8e094b3a724ef49cc91e5a1043118e",
            "a0ff38e195274b9c88c9bf091c37b878",
            "6d740474eeb543ce8f82c815aa20ba92",
            "2d0ddbc12f294cdbb1d81af6972d297b",
            "9730cf2a435547859deeafe094157af1",
            "af33fbdaa7d5454ba2912e926e0983e6",
            "2ccee74c79174c12ade9749530273a79",
            "b926ae1114da42a7ac8a06d5fab19052",
            "b5999880116240b6be4abafd03bdf465",
            "013af6ff2abb4887bc0083ac25eb4bc4",
            "9315e32562f447e9a5ad1c7ba5914290",
            "f7c58b3fb059488ca874bafec7029331",
            "ac39156c6e0248fdac42d319fd9107a3",
            "6b61fed89f24452fad15fc7a471c0c44",
            "6a320caa3e0f44e38a81d938c1378290",
            "ae2f8387629f4e8c8ac8cc638a834857",
            "39cb878de9764d9bb8f21287d10db0ba",
            "9e61f5f22b394c03abefde06acfadab8",
            "3d4ceda69d324c428db8b37233407bca",
            "0cc1209a41f144a88eda0cc08bf8b197",
            "a3a51d2f527e482b931b6c7af2eb0f19",
            "556a21f0444844dd97cca893186e1a92",
            "b04c7ea8785a447e802655232ec84fc8",
            "100c386dbc3e4ffe84d1f439da033621",
            "36d26ab93d56453aa5a5bbdc8108a284",
            "f94a1ca507ee45b791b6cf88c6268139",
            "d22bed276a7e48f1a35f75a528ea5b48",
            "92872c5ab7f744d1840cf674d7326941",
            "22e709717054463d908a515f51ad7ddc",
            "6ad0e362799b4682bdca5bce729add6d",
            "b978845031c04cf8a7483bfca4351df5",
            "bfbddc16845941c89740578c4d72eacb",
            "eecf0160ed074ee6b0df8b5ef62d730f",
            "3ad582e59d284ba283b0b8dcfa43c22b",
            "f71a04d7f89448dc9a0cda33e42cf5cf",
            "2b80d54499624c65888b9018d8427280",
            "aea25a9b92964a688979aebaec872d94"
          ]
        },
        "outputId": "9ae786f6-cab4-4f4b-a818-cd3b99d8aaec",
        "id": "2bcwWcAaqhG8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 171 chunks\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/794 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b9ad0e620594c61802da9b580f167c8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d062d9b691294f1d8d17a8e0848cae24"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9730cf2a435547859deeafe094157af1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae2f8387629f4e8c8ac8cc638a834857"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d22bed276a7e48f1a35f75a528ea5b48"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Coherence Score: 0.5494\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "004d6d5e-f0e5-4d58-8ec0-30c377df3308",
        "id": "p6IsWma_qhG9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 137 chunks\n",
            "Coherence Score: 0.5909\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00d44d85-04d0-44fa-d54a-e27f6eed6574",
        "id": "0Bl5f9UEqhG-"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 92 chunks\n",
            "Coherence Score: 0.5980\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3842e77-c8d4-4bd8-c3c2-d814369014b1",
        "id": "UWtAZQI0qhG_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 83 chunks\n",
            "Coherence Score: 0.7029\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be832e46-3ae5-47a5-8583-a069d0bdd07b",
        "id": "nsrrVqQtqhHA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 70 chunks\n",
            "Coherence Score: 0.7372\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #7: \"231161_OperationsMaintenanceManual.pdf\""
      ],
      "metadata": {
        "id": "H5MQDr5aqhHB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/231161_OperationsMaintenanceManual.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is the first step in the backup procedures?\", \"Describe procedures\"),\n",
        "    (\"Explain the processing overview\", \"Provide information\")\n",
        "]"
      ],
      "metadata": {
        "id": "VsQtcpjMqhHC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7011f62-ed99-4b1f-98d2-2001ec88cf45",
        "id": "INSN1aQrqhHD"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 68 chunks\n",
            "Coherence Score: 0.6021\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1524b15-c61a-4bd2-e33f-01796ae3a3c9",
        "id": "ahmHEK8sqhHE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 59 chunks\n",
            "Coherence Score: 0.6603\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e74916f-6c17-4f93-e008-df9ecdb00fb3",
        "id": "xvaAU6dMqhHE"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 38 chunks\n",
            "Coherence Score: 0.6648\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "635b4556-6a25-4d2c-afba-4c6d2113fc1a",
        "id": "W9EAQvd7qhHF"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 36 chunks\n",
            "Coherence Score: 0.6850\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c04a7c28-94eb-4fd6-a96d-f8afacb821a0",
        "id": "0k-ElGCLqhHG"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 35 chunks\n",
            "Coherence Score: 0.6981\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #8: \"SUPO-744_REV_A.pdf\""
      ],
      "metadata": {
        "id": "rSRTEUadqhHH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/SUPO-744_REV_A.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is the purpose of this Maintenance Manual \", \"provide qualified service personnel with information\"),\n",
        "    (\"What does 'CAUTION' indicate?\", \"potentially hazardous situation\")\n",
        "]"
      ],
      "metadata": {
        "id": "WbGQICRBqhHH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f79534b4-24f0-4377-a1de-61fded92e6eb",
        "id": "KJJsCW_CqhHI"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 92 chunks\n",
            "Coherence Score: 0.5655\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c3dc771-8676-4e06-e2da-64ab303dc972",
        "id": "BvFOv95DqhHJ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 83 chunks\n",
            "Coherence Score: 0.6009\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14cdc5b0-70d8-4c01-abb1-b77bc44d013a",
        "id": "r-YFGsnhqhHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 56 chunks\n",
            "Coherence Score: 0.5846\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc950ae5-3e2f-4c7d-e996-e5efe272ea13",
        "id": "dEXZ2UFVqhHK"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 53 chunks\n",
            "Coherence Score: 0.6607\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1040075-2ee5-4512-ab5f-f5e5d4cee230",
        "id": "w6kqtIidqhHL"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 54 chunks\n",
            "Coherence Score: 0.6794\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #9: \"VVS005s_030s_AHU_EN.pdf\""
      ],
      "metadata": {
        "id": "8HV63ecqqhHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/VVS005s_030s_AHU_EN.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is the first step in air handling units delivery?\", \"inspect all components\"),\n",
        "    (\"Recommended pressure control operating position for electric heaters?\", \"horizontal\")\n",
        "]"
      ],
      "metadata": {
        "id": "P24dlBgSqhHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45d74ae3-594a-4590-96b9-81fd45a9955f",
        "id": "AJSNvqRjqhHN"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 232 chunks\n",
            "Coherence Score: 0.5637\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d1f985-f704-42d6-f1f9-1510e2c6f48c",
        "id": "FQqIVnjoqhHO"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 204 chunks\n",
            "Coherence Score: 0.6485\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aca7c9a3-ef4c-4436-8b12-98103c0ada80",
        "id": "EFgY_Kj5qhHP"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 126 chunks\n",
            "Coherence Score: 0.6467\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dba65568-85b3-4e3e-b026-badf535aebdf",
        "id": "WNg3Kw1MqhHR"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 132 chunks\n",
            "Coherence Score: 0.7087\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c25bc6c-78b7-4760-ae05-389704e760f5",
        "id": "kbGHdEf0qhHS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 117 chunks\n",
            "Coherence Score: 0.7191\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    }
  ]
}