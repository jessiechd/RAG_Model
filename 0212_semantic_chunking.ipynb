{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO3YCJzkSF/l9gEGnH1TQoe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jessiechd/RAG_Model/blob/main/0212_semantic_chunking.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U sentence-transformers rouge  --q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zt1Xf4PeBYOU",
        "outputId": "11d91613-f584-40da-f2c6-f3228707ffdd"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Semantic Chunking: Testing with documents\n",
        "- variations in minimum sentences per chunk and overlaps\n",
        "- coherence score for evaluation"
      ],
      "metadata": {
        "id": "dJUK_evyIGWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import rouge\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "hoxlVlHFIWwW"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TextChunker2:\n",
        "    def __init__(self, model_name='sentence-transformers/all-mpnet-base-v1'):\n",
        "        self.model = SentenceTransformer(model_name)\n",
        "\n",
        "    def process_file(self, file_path, dynamic_window=True, min_chunk_size=3, overlap=1, num_clusters=5):\n",
        "        # Step 1: Load and encode text\n",
        "        sentences = self._load_text(file_path)\n",
        "        contextualized = self._add_dynamic_context(sentences) if dynamic_window else self._add_fixed_context(sentences)\n",
        "        embeddings = self.model.encode(contextualized)\n",
        "\n",
        "        # Step 2: Compute cosine distances between consecutive embeddings\n",
        "        distances = self._calculate_distances(embeddings)\n",
        "\n",
        "        # Step 3: Identify breakpoints based on semantic gaps\n",
        "        breakpoints = self._identify_breakpoints(distances, num_clusters)\n",
        "\n",
        "        # Step 4: Create initial chunks with overlap\n",
        "        initial_chunks = self._create_chunks(sentences, breakpoints, overlap)\n",
        "\n",
        "        # Step 5: Merge small chunks for better coherence\n",
        "        if min_chunk_size > 1:  # Ensure chunks are not too small\n",
        "            chunk_embeddings = self.model.encode(initial_chunks)\n",
        "            final_chunks = self._merge_small_chunks(initial_chunks, chunk_embeddings, min_chunk_size)\n",
        "        else:\n",
        "            final_chunks = initial_chunks  # Skip merging if min_chunk_size is 1\n",
        "\n",
        "        return final_chunks\n",
        "\n",
        "\n",
        "    def _load_text(self, file_path):\n",
        "        with open(file_path, 'r', encoding='utf-8') as file:\n",
        "            text = file.read()\n",
        "        return sent_tokenize(text)\n",
        "\n",
        "    def _add_fixed_context(self, sentences, window_size=1):\n",
        "        return [' '.join(sentences[max(0, i-window_size): min(len(sentences), i+window_size+1)]) for i in range(len(sentences))]\n",
        "\n",
        "    def _add_dynamic_context(self, sentences):\n",
        "        contextualized = []\n",
        "        embeddings = self.model.encode(sentences)\n",
        "        for i in range(len(sentences)):\n",
        "            similarities = cosine_similarity([embeddings[i]], embeddings)[0]\n",
        "            closest_indices = np.argsort(-similarities)[:3]  # Select 2 most relevant neighbors\n",
        "            context = ' '.join(sentences[j] for j in sorted(closest_indices))\n",
        "            contextualized.append(context)\n",
        "        return contextualized\n",
        "\n",
        "    def _identify_breakpoints(self, distances, threshold_percentile=90):\n",
        "        \"\"\"Find breakpoints where semantic distance is high.\"\"\"\n",
        "        threshold = np.percentile(distances, threshold_percentile)  # Dynamic threshold\n",
        "        return [i for i, dist in enumerate(distances) if dist > threshold]\n",
        "\n",
        "    # def _identify_breakpoints(self, distances, num_clusters=3):\n",
        "    #     distances = np.array(distances).reshape(-1, 1)  # Reshape for clustering\n",
        "    #     kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    #     kmeans.fit(distances)\n",
        "    #     labels = kmeans.labels_\n",
        "\n",
        "    #     # Find cluster with highest distance values\n",
        "    #     breakpoint_cluster = np.argmax(kmeans.cluster_centers_)\n",
        "    #     return [i for i, label in enumerate(labels) if label == breakpoint_cluster]\n",
        "\n",
        "    def _create_chunks(self, sentences, breakpoints, overlap=1):\n",
        "        chunks = []\n",
        "        start_idx = 0\n",
        "\n",
        "        for breakpoint in breakpoints:\n",
        "            end_idx = breakpoint + 1\n",
        "            chunk = ' '.join(sentences[max(0, start_idx - overlap):end_idx])\n",
        "            chunks.append(chunk)\n",
        "            start_idx = end_idx\n",
        "\n",
        "        final_chunk = ' '.join(sentences[max(0, start_idx - overlap):])\n",
        "        chunks.append(final_chunk)\n",
        "\n",
        "        return chunks\n",
        "\n",
        "    def _merge_small_chunks(self, chunks, embeddings, min_size):\n",
        "        final_chunks, merged_embeddings = [chunks[0]], [embeddings[0]]\n",
        "        for i in range(1, len(chunks) - 1):\n",
        "            if len(chunks[i].split('. ')) < min_size:\n",
        "                prev_sim = cosine_similarity([embeddings[i]], [merged_embeddings[-1]])[0][0]\n",
        "                next_sim = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "                if prev_sim > next_sim:\n",
        "                    final_chunks[-1] += ' ' + chunks[i]\n",
        "                    merged_embeddings[-1] = (merged_embeddings[-1] + embeddings[i]) / 2\n",
        "                else:\n",
        "                    chunks[i + 1] = chunks[i] + ' ' + chunks[i + 1]\n",
        "                    embeddings[i + 1] = (embeddings[i] + embeddings[i + 1]) / 2\n",
        "            else:\n",
        "                final_chunks.append(chunks[i])\n",
        "                merged_embeddings.append(embeddings[i])\n",
        "        final_chunks.append(chunks[-1])\n",
        "        return final_chunks\n",
        "\n",
        "    def _calculate_distances(self, embeddings):\n",
        "      \"\"\"Calculate cosine distances between consecutive embeddings.\"\"\"\n",
        "      distances = []\n",
        "      for i in range(len(embeddings) - 1):\n",
        "          similarity = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "          distance = 1 - similarity  # Distance = 1 - similarity\n",
        "          distances.append(distance)\n",
        "      return distances\n",
        "\n",
        "    def evaluate_coherence(self, chunks):\n",
        "        coherence_scores = []\n",
        "        embeddings = self.model.encode(chunks)\n",
        "        for i in range(len(embeddings) - 1):\n",
        "            score = cosine_similarity([embeddings[i]], [embeddings[i + 1]])[0][0]\n",
        "            coherence_scores.append(score)\n",
        "        return np.mean(coherence_scores)\n",
        "\n",
        "    def evaluate_rouge(self, original_text, chunks):\n",
        "        rouge_evaluator = rouge.Rouge()\n",
        "        scores = [rouge_evaluator.get_scores(chunk, original_text)[0]['rouge-1']['f'] for chunk in chunks]\n",
        "        return np.mean(scores)\n",
        "\n",
        "    def evaluate_qa_performance(self, chunks, test_questions):\n",
        "        chunk_embeddings = self.model.encode(chunks)\n",
        "\n",
        "        def retrieve_best_chunk(query):\n",
        "            from sentence_transformers import CrossEncoder\n",
        "            reranker = CrossEncoder(\"cross-encoder/ms-marco-MiniLM-L-6-v2\")\n",
        "\n",
        "            query_embedding = self.model.encode([query])\n",
        "            similarities = cosine_similarity(query_embedding, chunk_embeddings)[0]\n",
        "            top_n = np.argsort(similarities)[-3:]\n",
        "            rerank_scores = reranker.predict([[query, chunks[i]] for i in top_n])\n",
        "            return chunks[top_n[np.argmax(rerank_scores)]]\n",
        "\n",
        "        correct = 0\n",
        "        for question, expected_answer in test_questions:\n",
        "            retrieved_chunk = retrieve_best_chunk(question)\n",
        "            if expected_answer in retrieved_chunk:\n",
        "                correct += 1\n",
        "\n",
        "        return correct / len(test_questions)\n"
      ],
      "metadata": {
        "id": "PSb1Qq2vIIn0"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "chunker2 = TextChunker2()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvHGyaQ8pHIc",
        "outputId": "3ebdb8c3-cce7-4c2f-984a-29e3afdaaa91"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #1: \"17.pdf\""
      ],
      "metadata": {
        "id": "KuG56cs15Fmr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/17_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Where does the family medicine training take place?\", \"Africa\")\n",
        "]"
      ],
      "metadata": {
        "id": "p9H7ywMINxGf"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chunker_test(mcs, ovl):\n",
        "    chunks2 = chunker2.process_file(\n",
        "        file_path,\n",
        "        dynamic_window=True,\n",
        "        min_chunk_size=mcs,\n",
        "        overlap=ovl,\n",
        "        num_clusters=3)\n",
        "\n",
        "    print(f\"Using min_chunk_size={mcs}, overlap={ovl}\")\n",
        "\n",
        "    # Print results\n",
        "    print(f\"Successfully split text into {len(chunks2)} chunks\")\n",
        "\n",
        "    # for i in range(len(chunks2)):\n",
        "    #     print(f\"Chunk {i+1}: {len(chunks2[i].split('. '))} sentences\")\n",
        "\n",
        "    # Compute evaluation metrics\n",
        "    coherence_score = chunker2.evaluate_coherence(chunks2)\n",
        "    # rouge_score = chunker2.evaluate_rouge(text, chunks2)  # Fixed variable\n",
        "    qa_accuracy = chunker2.evaluate_qa_performance(chunks2, test_questions)  # Removed retrieval_system\n",
        "\n",
        "    # Print evaluation results\n",
        "    print(f\"Coherence Score: {coherence_score:.4f}\")\n",
        "    # print(f\"ROUGE Score: {rouge_score:.4f}\")\n",
        "    print(f\"QA Accuracy: {qa_accuracy * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "WtlFKDW2CQ6N"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jHxpBpGGon1Q",
        "outputId": "a7623b34-3829-4662-e006-1f43c9e5fda0"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 102 chunks\n",
            "Coherence Score: 0.5870\n",
            "ROUGE Score: 0.0593\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMtq45_0Cc_2",
        "outputId": "f3fc71d2-7a04-4c48-b181-792a8bfc2000"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 80 chunks\n",
            "Coherence Score: 0.6504\n",
            "ROUGE Score: 0.0835\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dwA4jFXZCgrC",
        "outputId": "0fab1a66-7ff4-4141-980f-4e8714822b53"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 58 chunks\n",
            "Coherence Score: 0.7273\n",
            "ROUGE Score: 0.1122\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43G0V091CiXp",
        "outputId": "245b2b1a-a901-4176-db46-cfeac4520355"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 52 chunks\n",
            "Coherence Score: 0.7788\n",
            "ROUGE Score: 0.1448\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vXS7OsmhCkUQ",
        "outputId": "23e68c48-5635-4b25-b729-292f619a3673"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 51 chunks\n",
            "Coherence Score: 0.7969\n",
            "ROUGE Score: 0.1585\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #2: \"PDF1.pdf\""
      ],
      "metadata": {
        "id": "OXp3RsPIo810"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/PDF1_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Which industry sector does the study focus on?\", \"semiconductor\"),\n",
        "    (\"WWhat machine learning subfield is sentiment analysis a part of?\", \"NLP\")\n",
        "]"
      ],
      "metadata": {
        "id": "zKxz5AarAYiw"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52721854-a262-4266-b189-829603d696da",
        "id": "tauoiV-7Cpee"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 202 chunks\n",
            "Coherence Score: 0.5717\n",
            "ROUGE Score: 0.0371\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pl2WzF5VCpee",
        "outputId": "d6a3baf2-f728-4f7f-8a9f-33a8213ac05a"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 174 chunks\n",
            "Coherence Score: 0.6755\n",
            "ROUGE Score: 0.0497\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vfo8aPQ1Cpef",
        "outputId": "edee4c17-502b-4efa-bd59-0fd7f919b7f5"
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 120 chunks\n",
            "Coherence Score: 0.6795\n",
            "ROUGE Score: 0.0679\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dl2_C9kFCpef",
        "outputId": "239548f8-83ec-4125-e911-0edbc50322ee"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 109 chunks\n",
            "Coherence Score: 0.7519\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "baSa1lvACpef",
        "outputId": "a0a94a4d-4fe8-4459-a691-48ca781f6523"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 105 chunks\n",
            "Coherence Score: 0.7688\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #3: \"2024_11_05 - Ferrari Q3 2024 Results Press Release.pdf\""
      ],
      "metadata": {
        "id": "K5_e2rQADX3R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/2024_11_05 - Ferrari Q3 2024 Results Press Release_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"Where is Ferrari's factory located?\", \"Maranello\"),\n",
        "    (\"What is the brand this document mentioned?\", \"Ferrari\")\n",
        "]"
      ],
      "metadata": {
        "id": "CLzpdaE_DX3S"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1f3c045-36c6-46c7-99ad-e8fd99bc4da2",
        "id": "kPr4DIC7DX3S"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 53 chunks\n",
            "Coherence Score: 0.5453\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3PjB_YqmDX3T",
        "outputId": "bad202ce-c27c-489d-ad0b-d676dbe9b1c3"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 42 chunks\n",
            "Coherence Score: 0.5961\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OHaulj-DDX3T",
        "outputId": "7b1d104e-9281-47ea-f83b-8203bdc40753"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 32 chunks\n",
            "Coherence Score: 0.6668\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0JVV11xSDX3T",
        "outputId": "3bd3fa81-94c2-498c-af51-5b6370150383"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 24 chunks\n",
            "Coherence Score: 0.6642\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCcU474SDX3U",
        "outputId": "6dc5e68e-3ff7-488b-de2d-7ea6a9e15e3a"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 26 chunks\n",
            "Coherence Score: 0.7087\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #4: \"ai-in-america-oai-economic-blueprint-20250113.pdf\""
      ],
      "metadata": {
        "id": "9qxvV-voGCiW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/ai-in-america-oai-economic-blueprint-20250113_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is OpenAI's mission?\", \"benefits everyone\"),\n",
        "    (\"How many people are currently using OpenAI's tools?\", \"300 million\")\n",
        "]"
      ],
      "metadata": {
        "id": "gyLRO4jtGCiX"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpF-aUrkGCiX",
        "outputId": "8de6ac34-1822-4bc8-a384-8d1c45d7a0af"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 74 chunks\n",
            "Coherence Score: 0.5756\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SlXsvEhpGCiY",
        "outputId": "653f178c-15ae-428a-e6a6-52b53566c574"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 68 chunks\n",
            "Coherence Score: 0.6318\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOoTTXeYGCiY",
        "outputId": "7ad15bf7-ada8-4270-9479-296329009426"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 42 chunks\n",
            "Coherence Score: 0.6412\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIJlPXU1GCiY",
        "outputId": "5fbe79fb-0a38-4a9f-9de4-7b7c4eee00a1"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 46 chunks\n",
            "Coherence Score: 0.7270\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iZhnoAJHGCiY",
        "outputId": "f97c4402-9b6e-4687-ced5-55a4552abd5c"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 39 chunks\n",
            "Coherence Score: 0.7016\n",
            "QA Accuracy: 0.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing with Document #5: \"creatingsystem.pdf\""
      ],
      "metadata": {
        "id": "r7sI95dUK1Cf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "file_path = \"/content/creatingsystem_qwen1.md\"\n",
        "\n",
        "with open(file_path, \"r\", encoding=\"utf-8\") as f:\n",
        "    text = f.read()\n",
        "\n",
        "test_questions = [\n",
        "    (\"What is a water system operations and maintenance manual?\", \"comprehensive 'how-to' guidance document\"),\n",
        "    (\"Why is the manual necessary?\", \"detailed resource\")\n",
        "]"
      ],
      "metadata": {
        "id": "rUaRSQbQK1Cg"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 3\n",
        "ovl = 1\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "145ea7c0-74b1-4607-d978-5a3a8cc54bd8",
        "id": "MqeLsvicK1Cg"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=3, overlap=1\n",
            "Successfully split text into 6 chunks\n",
            "Coherence Score: 0.6066\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 5\n",
        "ovl = 2\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6thLzuZKK1Cg",
        "outputId": "8e8b7be9-e58b-42ec-a3d4-4aeeabf5baa5"
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=5, overlap=2\n",
            "Successfully split text into 5 chunks\n",
            "Coherence Score: 0.6121\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 10\n",
        "ovl = 3\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H1eaa6vwK1Ch",
        "outputId": "b0be1bc9-52d7-448d-98f3-8c01aed2926e"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=10, overlap=3\n",
            "Successfully split text into 3 chunks\n",
            "Coherence Score: 0.3867\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 15\n",
        "ovl = 5\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zmiq9EZAK1Ch",
        "outputId": "861afbcb-d61c-4b96-91e6-cb5bfbab899a"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=15, overlap=5\n",
            "Successfully split text into 4 chunks\n",
            "Coherence Score: 0.5249\n",
            "QA Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mcs = 20\n",
        "ovl = 6\n",
        "chunker_test(mcs, ovl)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M7Sc2naqK1Ch",
        "outputId": "747b306b-9dbc-46a2-8b1f-54f867996b3e"
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using min_chunk_size=20, overlap=6\n",
            "Successfully split text into 3 chunks\n",
            "Coherence Score: 0.3822\n",
            "QA Accuracy: 50.00%\n"
          ]
        }
      ]
    }
  ]
}