{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iDo-3Rl0jy7e"
      },
      "source": [
        "**updates:**\n",
        "\n",
        "- added function to ignore tiny images (less than 50x50 pixels) as the Qwen model cannot read them anyway\n",
        "- function to entirely delete duplicate images\n",
        "- now uses `nodes.json` files as input instead of `.md` files\n",
        "- added function to extract singular images: `process_single_image`\n",
        "\n",
        "\n",
        "**issues and possible improvements/changes:**\n",
        "- limitation in `find_and_remove_duplicates` function: sometimes visually identical images cannot be considered as 'duplicates' if they have slightly different dimensions, formats, or metadata"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8YxV-6PLcdaR"
      },
      "source": [
        "# Requirements"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Bixc2YnfC4Ow",
        "outputId": "df33214b-d09e-4ca6-ef80-bc77153f104f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers accelerate numpy Requests torch torchvision qwen-vl-utils av ipython reportlab fpdf python-docx pillow huggingface_hub --quiet\n",
        "!pip install git+https://github.com/huggingface/transformers accelerate --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "d_6xwdLobIDY"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import Qwen2VLForConditionalGeneration, AutoProcessor, TextIteratorStreamer\n",
        "from qwen_vl_utils import process_vision_info\n",
        "from PIL import Image\n",
        "import uuid\n",
        "import io\n",
        "from threading import Thread\n",
        "# from reportlab.lib.pagesizes import A4\n",
        "# from reportlab.lib.styles import getSampleStyleSheet\n",
        "# from reportlab.platypus import SimpleDocTemplate, Image as RLImage, Paragraph, Spacer\n",
        "# from reportlab.lib.units import inch\n",
        "# from reportlab.pdfbase import pdfmetrics\n",
        "# from reportlab.pdfbase.ttfonts import TTFont\n",
        "import docx\n",
        "# from docx.enum.text import WD_ALIGN_PARAGRAPH\n",
        "import json"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "imV0CA4Lya1l"
      },
      "source": [
        "# Qwen functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gCBAleWG4bmd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "7138a35df63f47a18a069aef0c62ea4f",
            "f47ed02c21e84cb8b02a6b5439d37a9c",
            "73c7b022daa04280abd3308bfddf4b81",
            "f7d14b3b707d434aa334210682753204",
            "6cf67238d90f46f9a07d0a11a5337e74",
            "41c2606ee65e49158970422cbf89f262",
            "df433ddcc99a4b91875c681c60d2d10f",
            "2f7bab44c9c9416ca6be772c9c25563b",
            "aaa6fe289a26433eab1ce9b53771d104",
            "b2800ec3f7a2415bb1f872204bf9c6ac",
            "b1fb35a6ee7447c3844ade79eb2151cb"
          ]
        },
        "outputId": "4d135b2f-df5e-4b23-86b6-2d229c0d05c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n",
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7138a35df63f47a18a069aef0c62ea4f"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Load the model and processor\n",
        "model_name = \"Qwen/Qwen2-VL-2B-Instruct\"\n",
        "\n",
        "model = Qwen2VLForConditionalGeneration.from_pretrained(model_name, trust_remote_code=True, torch_dtype=torch.float32).to(\"cpu\").eval()\n",
        "\n",
        "processor = AutoProcessor.from_pretrained(model_name, trust_remote_code=True)\n",
        "\n",
        "image_extensions = Image.registered_extensions()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lkXLmcmz_DnF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "torch.cuda.empty_cache()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "OcLX1gIDDDOP"
      },
      "outputs": [],
      "source": [
        "import base64\n",
        "def identify_and_save_blob(blob_path):\n",
        "    \"\"\"Identifies if the blob is an image and saves it.\"\"\"\n",
        "    try:\n",
        "        with open(blob_path, 'rb') as file:\n",
        "            blob_content = file.read()\n",
        "            try:\n",
        "                Image.open(io.BytesIO(blob_content)).verify()  # Check if it's a valid image\n",
        "                extension = \".png\"  # Default to PNG for saving\n",
        "                media_type = \"image\"\n",
        "            except (IOError, SyntaxError):\n",
        "                raise ValueError(\"Unsupported media type. Please upload a valid image.\")\n",
        "\n",
        "            filename = f\"temp_{uuid.uuid4()}_media{extension}\"\n",
        "            with open(filename, \"wb\") as f:\n",
        "                f.write(blob_content)\n",
        "\n",
        "            return filename, media_type\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        raise ValueError(f\"The file {blob_path} was not found.\")\n",
        "    except Exception as e:\n",
        "        raise ValueError(f\"An error occurred while processing the file: {e}\")\n",
        "\n",
        "def decode_base64_to_image(base64_string):\n",
        "    \"\"\"Decodes a base64 string and saves it as a temporary image file.\"\"\"\n",
        "    image_data = base64.b64decode(base64_string)\n",
        "    image = Image.open(io.BytesIO(image_data))\n",
        "\n",
        "    filename = f\"temp_{uuid.uuid4()}.png\"  # Always save as PNG\n",
        "    image.save(filename)\n",
        "\n",
        "    return filename\n",
        "\n",
        "def qwen_inference(media_input, text_input=None):\n",
        "    torch.cuda.empty_cache()\n",
        "    # torch.cuda.memory_summary(device=None, abbreviated=False)\n",
        "    \"\"\"Handles inference for the selected model.\"\"\"\n",
        "    if media_input.startswith(\"data:image\"):  # Detect base64 input\n",
        "            base64_str = media_input.split(\",\")[1]  # Remove the base64 header\n",
        "            media_path = decode_base64_to_image(base64_str)\n",
        "    elif media_input.endswith(tuple(image_extensions.keys())):  # If it's a file path\n",
        "            media_path = media_input\n",
        "    else:\n",
        "            raise ValueError(\"Unsupported media type. Please provide a valid image path or base64 string.\")\n",
        "    media_type = \"image\"\n",
        "    messages = [\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": media_type,\n",
        "                    media_type: media_path\n",
        "                },\n",
        "                {\"type\": \"text\", \"text\": text_input},\n",
        "            ],\n",
        "        }\n",
        "    ]\n",
        "\n",
        "    text = processor.apply_chat_template(\n",
        "        messages, tokenize=False, add_generation_prompt=True\n",
        "    )\n",
        "    image_inputs, _ = process_vision_info(messages)\n",
        "    inputs = processor(\n",
        "        text=[text],\n",
        "        images=image_inputs,\n",
        "        padding=True,\n",
        "        return_tensors=\"pt\",\n",
        "    ).to(\"cpu\")\n",
        "\n",
        "    # Run the model in a separate thread\n",
        "    streamer = TextIteratorStreamer(\n",
        "        processor.tokenizer, skip_prompt=True, skip_special_tokens=True\n",
        "    )\n",
        "    generation_kwargs = dict(inputs, streamer=streamer, max_new_tokens=1024)\n",
        "\n",
        "    thread = Thread(target=model.generate, kwargs=generation_kwargs)\n",
        "    thread.start()\n",
        "\n",
        "    buffer = \"\"\n",
        "    for new_text in streamer:\n",
        "        buffer += new_text\n",
        "        # Remove <|im_end|> or similar tokens from the output\n",
        "        buffer = buffer.replace(\"<|im_end|>\", \"\")\n",
        "        yield buffer\n",
        "\n",
        "def format_plain_text(output_text):\n",
        "    \"\"\"Formats the output text as plain text without LaTeX delimiters.\"\"\"\n",
        "    # Remove LaTeX delimiters and convert to plain text\n",
        "    plain_text = output_text.replace(\"\\\\(\", \"\").replace(\"\\\\)\", \"\").replace(\"\\\\[\", \"\").replace(\"\\\\]\", \"\")\n",
        "    return plain_text\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wlkPL6FBF-Y5"
      },
      "outputs": [],
      "source": [
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ym3i-bFdygyQ"
      },
      "source": [
        "# Image handling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "uJgs2mld470N"
      },
      "outputs": [],
      "source": [
        "# deleting duplicate images\n",
        "import hashlib\n",
        "import os\n",
        "import re\n",
        "import glob\n",
        "\n",
        "\n",
        "def calculate_hash(image_path):\n",
        "    \"\"\"Calculate the hash of an image.\"\"\"\n",
        "    try:\n",
        "        with Image.open(image_path) as img:\n",
        "            img = img.resize((256, 256)).convert(\"RGB\")  # Resize and standardize\n",
        "            return hashlib.md5(img.tobytes()).hexdigest()\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing {image_path}: {e}\")\n",
        "        return None\n",
        "\n",
        "def find_and_remove_duplicates(folder_path):\n",
        "    \"\"\"Find and remove duplicate images in the given folder.\"\"\"\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"The folder '{folder_path}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    hashes = {}\n",
        "    duplicates = []\n",
        "\n",
        "    for root, _, files in os.walk(folder_path):\n",
        "        for file in files:\n",
        "            file_path = os.path.join(root, file)\n",
        "            if file.lower().endswith((\".png\", \".jpg\", \".jpeg\", \".bmp\", \".gif\", \".tiff\")):\n",
        "                img_hash = calculate_hash(file_path)\n",
        "                if img_hash:\n",
        "                    if img_hash in hashes:\n",
        "                        duplicates.append(file_path)\n",
        "                    else:\n",
        "                        hashes[img_hash] = file_path\n",
        "\n",
        "    # Remove duplicates\n",
        "    for duplicate in duplicates:\n",
        "        try:\n",
        "            os.remove(duplicate)\n",
        "            print(f\"Deleted: {duplicate}\")\n",
        "        except Exception as e:\n",
        "            print(f\"Could not delete {duplicate}: {e}\")\n",
        "\n",
        "    print(f\"Total duplicates removed: {len(duplicates)}\")\n",
        "\n",
        "def remove_small_images(image_folder, min_size=50):\n",
        "    \"\"\"Deletes images smaller than min_size x min_size pixels.\"\"\"\n",
        "    len = 0\n",
        "    for img_file in glob.glob(os.path.join(image_folder, \"*.*\")):\n",
        "        try:\n",
        "            with Image.open(img_file) as img:\n",
        "                if img.size[0] < min_size or img.size[1] < min_size:\n",
        "                    os.remove(img_file)\n",
        "                    print(f\"Deleted: {img_file}\")\n",
        "                    len = len+1\n",
        "        except Exception:\n",
        "            continue\n",
        "    print(f\"Total small images removed: {len}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1jz3UNlyloQ"
      },
      "source": [
        "# Image extraction from nodes + Qwen processing functions"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import re\n",
        "from PIL import Image\n",
        "\n",
        "def update_json(json_file, json_folder):\n",
        "    \"\"\"Updates JSON by removing nodes with missing images and renewing indexes.\"\"\"\n",
        "\n",
        "    # Load JSON file\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    filename = os.path.basename(json_file).replace(\"_all_nodes_with_images.json\", \"\")\n",
        "    # Get list of actual image files in the same folder\n",
        "    artifacts_folder = filename + \"_artifacts\"\n",
        "    img_folder = os.path.join(json_folder, artifacts_folder)\n",
        "    valid_images = set(os.listdir(img_folder))  # Images that exist in json_folder\n",
        "\n",
        "\n",
        "    new_nodes = []\n",
        "    index_counter = 1\n",
        "\n",
        "    for node in data[\"nodes\"]:\n",
        "        if node.get(\"image_path\"):  # If node has an image\n",
        "            image_name = os.path.basename(node[\"image_path\"])\n",
        "            if image_name not in valid_images:\n",
        "                continue  # Skip nodes where the image is missing\n",
        "\n",
        "        # Trim text field to max 3000 characters\n",
        "        if \"text\" in node and isinstance(node[\"text\"], str):\n",
        "            node[\"text\"] = node[\"text\"][:3000]  # Keep only the first 3000 characters\n",
        "\n",
        "        node[\"index\"] = index_counter  # Update index sequentially\n",
        "        new_nodes.append(node)\n",
        "        index_counter += 1\n",
        "\n",
        "    # Update JSON metadata\n",
        "    data[\"nodes\"] = new_nodes\n",
        "    data[\"number_of_nodes\"] = len(new_nodes)\n",
        "\n",
        "    # Save new JSON file\n",
        "    new_json_file = os.path.join(json_folder, os.path.basename(json_file).replace(\".json\", \"_updated.json\"))\n",
        "    with open(new_json_file, \"w\", encoding=\"utf-8\") as file:\n",
        "        json.dump(data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Updated JSON saved as: {new_json_file}\")\n",
        "    return new_json_file\n",
        "\n",
        "\n",
        "\n",
        "def process_image(image_path, context_text, json_folder):\n",
        "    \"\"\"Generate explanation for an image using context from surrounding nodes.\"\"\"\n",
        "    media_input = os.path.join(json_folder, image_path)  # Construct full image path\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if not os.path.exists(media_input):\n",
        "        return \"\"\n",
        "\n",
        "    if not context_text.strip():\n",
        "        context_text = \"\"\n",
        "        text_input = f\"Explain the content of this image.\"\n",
        "    else:\n",
        "        text_input = f\"Explain the content of this image. The following context may help: {context_text}\"\n",
        "\n",
        "    print(f\"Processing: {image_path} with context.\")\n",
        "\n",
        "    output = list(qwen_inference(media_input, text_input))  # Call inference function\n",
        "    explanation = format_plain_text(output[-1])\n",
        "\n",
        "    return explanation"
      ],
      "metadata": {
        "id": "UWczz-dQccmP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split json file to max 50 nodes each file\n",
        "\n",
        "def split_nodes(json_file):\n",
        "    \"\"\"Splits a JSON file into smaller JSON files, each containing a max of 50 nodes.\"\"\"\n",
        "\n",
        "    # Load the original JSON file\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "\n",
        "    if \"nodes\" not in data or not isinstance(data[\"nodes\"], list):\n",
        "        raise ValueError(\"Invalid JSON structure: 'nodes' list not found.\")\n",
        "\n",
        "    base_name = os.path.basename(json_file).replace(\".json\", \"\")\n",
        "    json_folder = os.path.dirname(json_file)\n",
        "    nodes = data[\"nodes\"]\n",
        "    output_files = []\n",
        "\n",
        "    # Split nodes into chunks of 50\n",
        "    for i in range(0, len(nodes), 50):\n",
        "        chunk = nodes[i:i+50]\n",
        "\n",
        "        # Re-index nodes (1 to 50, 51 to 100, etc.)\n",
        "        for j, node in enumerate(chunk):\n",
        "            node[\"index\"] = i + j + 1  # Keeps original order but ensures sequential numbering per file\n",
        "\n",
        "        # Create smaller JSON with updated metadata\n",
        "        small_json = {\n",
        "            \"file_name\": data[\"file_name\"],\n",
        "            \"number_of_nodes\": len(chunk),\n",
        "            \"nodes\": chunk\n",
        "        }\n",
        "\n",
        "        small_json_file = os.path.join(json_folder, f\"{base_name}_part_{(i//50) + 1}.json\")\n",
        "\n",
        "        # Save smaller JSON file\n",
        "        with open(small_json_file, \"w\", encoding=\"utf-8\") as file:\n",
        "            json.dump(small_json, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "        output_files.append(small_json_file)\n",
        "        print(f\"Created: {small_json_file}\")\n",
        "\n",
        "    return output_files  # Return list of created JSON files\n",
        "\n",
        "\n",
        "def get_context(image_path, nodes):\n",
        "    \"\"\"Finds the surrounding text (previous & next nodes) for an image node.\"\"\"\n",
        "\n",
        "    for i, node in enumerate(nodes):\n",
        "        if \"image_path\" in node and node[\"image_path\"] == image_path:  # Locate image node\n",
        "            prev_text = nodes[i - 1][\"text\"] if i > 0 else \"\"  # Get previous text\n",
        "            next_text = nodes[i + 1][\"text\"] if i < len(nodes) - 1 else \"\"  # Get next text\n",
        "            return f\"{prev_text} {next_text}\".strip()  # Combine context\n",
        "\n",
        "    return \"\""
      ],
      "metadata": {
        "id": "V8eyWep4etv0"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_split_files(split_files, json_folder):\n",
        "    \"\"\"Processes each split JSON file, finds images, and adds explanations.\"\"\"\n",
        "\n",
        "    processed_files = []\n",
        "\n",
        "    for split_file in split_files:\n",
        "        # Load the split JSON file\n",
        "        with open(split_file, \"r\", encoding=\"utf-8\") as file:\n",
        "            data = json.load(file)\n",
        "\n",
        "        updated = False  # Track if changes were made\n",
        "\n",
        "        for node in data[\"nodes\"]:\n",
        "            if \"image_path\" in node and node[\"image_path\"]:  # If node has an image\n",
        "                image_path = os.path.join(json_folder, node[\"image_path\"])\n",
        "\n",
        "                if os.path.exists(image_path):  # Ensure image exists\n",
        "                    context = get_context(image_path, data[\"nodes\"])  # Get context\n",
        "                    explanation = process_image(image_path, context, json_folder)\n",
        "                    node[\"explanation\"] = explanation  # Update node\n",
        "                    updated = True  # Mark JSON as updated\n",
        "\n",
        "        if updated:\n",
        "            # Save the updated JSON with explanations\n",
        "            processed_file = split_file.replace(\".json\", \"_processed.json\")\n",
        "            with open(processed_file, \"w\", encoding=\"utf-8\") as file:\n",
        "                json.dump(data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "            processed_files.append(processed_file)\n",
        "            print(f\"Processed and saved: {processed_file}\")\n",
        "\n",
        "    return processed_files"
      ],
      "metadata": {
        "id": "0M4apFy3kle3"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "oFdEEw0IGEb7"
      },
      "outputs": [],
      "source": [
        "\n",
        "def process_json_file(json_file):\n",
        "    \"\"\"Processes images from a JSON file and updates the JSON with explanations.\"\"\"\n",
        "    json_folder = os.path.dirname(json_file)\n",
        "\n",
        "    # Load JSON file\n",
        "    with open(json_file, \"r\", encoding=\"utf-8\") as file:\n",
        "        data = json.load(file)\n",
        "    filename = os.path.basename(json_file).replace(\"_all_nodes_with_images.json\", \"\")\n",
        "\n",
        "    # image handling\n",
        "    artifacts_folder = filename + \"_artifacts\"\n",
        "    img_folder = os.path.join(json_folder, artifacts_folder)\n",
        "    find_and_remove_duplicates(img_folder)\n",
        "    remove_small_images(img_folder)\n",
        "\n",
        "    # new json file with updated images & indexes\n",
        "    updated_json = update_json(json_file, json_folder)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    split_json = split_nodes(updated_json)\n",
        "    processed_split = process_split_files(split_json, json_folder)\n",
        "\n",
        "    merged_output_file = filename + \"_qwen_processed.json\"\n",
        "\n",
        "    # Initialize the merged data structure\n",
        "    merged_data = {\"file_name\": \"merged_output\", \"number_of_nodes\": 0, \"nodes\": []}\n",
        "\n",
        "    # Iterate through each processed JSON file\n",
        "    for processed_file in processed_split:\n",
        "        with open(processed_file, \"r\", encoding=\"utf-8\") as file:\n",
        "            data = json.load(file)\n",
        "            merged_data[\"nodes\"].extend(data[\"nodes\"])  # Append nodes\n",
        "\n",
        "    # Update the total number of nodes\n",
        "    merged_data[\"number_of_nodes\"] = len(merged_data[\"nodes\"])\n",
        "\n",
        "    # Save the merged JSON file\n",
        "    with open(merged_output_file, \"w\", encoding=\"utf-8\") as file:\n",
        "        json.dump(merged_data, file, indent=4, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Merged JSON file saved as: {merged_output_file}\")\n",
        "\n",
        "    # Delete processed split files after merging\n",
        "    for processed_file in processed_split:\n",
        "        os.remove(processed_file)\n",
        "        print(f\"Deleted: {processed_file}\")\n",
        "\n",
        "    for processed_file in split_json:\n",
        "        os.remove(processed_file)\n",
        "        print(f\"Deleted: {processed_file}\")\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "vDuiToyv3k5u"
      },
      "outputs": [],
      "source": [
        "# process singular image\n",
        "def process_single_image(image_path):\n",
        "    \"\"\"Generate explanation for an image using context from surrounding nodes.\"\"\"\n",
        "    media_input = image_path  # Construct full image path\n",
        "\n",
        "    # Check if the image file exists\n",
        "    if not os.path.exists(media_input):\n",
        "      print(f\"The file '{media_input}' does not exist.\")\n",
        "      return \"\"\n",
        "\n",
        "    # Open image and check resolution\n",
        "    with Image.open(media_input) as img:\n",
        "        width, height = img.size\n",
        "        if width < 50 and height < 50:  # Skip very small images\n",
        "            print(f\"The file '{media_input}' is too small to process.\")\n",
        "            return \"\"\n",
        "\n",
        "    text_input = f\"Explain the content of this image.\"\n",
        "    print(f\"Processing: {image_path}\")\n",
        "\n",
        "    output = list(qwen_inference(media_input, text_input))  # Call inference function\n",
        "    explanation = format_plain_text(output[-1])\n",
        "\n",
        "    return explanation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uly2WXhvccND"
      },
      "source": [
        "# Begin processing files (nodes.json or singular image files)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "acs3tbgGB1pv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73916a61-8c8f-49f0-8a24-f3f268b1fb7b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "uMBP26DgDK-_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f96dc357-0965-44c5-adf9-dd24536d3163"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000008_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000003_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000002_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000011_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000012_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000005_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000014_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000004_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000010_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000007_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000009_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000013_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png\n",
            "Total duplicates removed: 12\n",
            "Total small images removed: 0\n",
            "Updated JSON saved as: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images_updated.json\n",
            "Created: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images_updated_part_1.json\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000000_61a6ea5e0aaf96d2c28bb487cb9ff155bca99b288f3e6dcdccfd929fada03176.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000001_8bb3466220ffdea455fbae5a9208274ed6aeba7f7128af73a0a39f10a71318ed.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_artifacts/image_000006_7a233a57531d7d54d98523821046bcaf2c26cafbe76faf12e86523665031d4fc.png with context.\n",
            "Processed and saved: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images_updated_part_1_processed.json\n",
            "Merged JSON file saved as: 2024_11_05_Ferrari_Q3_2024_Results_Press_Release_qwen_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images_updated_part_1_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images_updated_part_1.json\n"
          ]
        }
      ],
      "source": [
        "# Example usage: nodes.json file\n",
        "\n",
        "process_json_file(\"/content/drive/MyDrive/output-imagenodes/2024_11_05_Ferrari_Q3_2024_Results_Press_Release_all_nodes_with_images.json\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"/content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images.json\",\n",
        "        \"/content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images.json\",\n",
        "        \"/content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images.json\"\n",
        "]\n",
        "\n",
        "\n",
        "for file in files:\n",
        "  process_json_file(file)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EQsmfzN7s80p",
        "outputId": "fce421f5-e8d9-4609-9620-29158a021c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total duplicates removed: 0\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000005_5a0955a531f0009997d3cb2659e8288d4ce5999bfae8a5da04359a9f74b455a0.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000004_4623b4124fe5eb97219b501a4673b832f019b8eb43298a00779ffbd8a836c0e4.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000001_26f31da1da5cef304ea0d1b264f18dee0f281b9c70603e1dac0c9e3f3e051c25.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000000_88f21e2a2e3bdd78e1156c89d591de7a7a5ed7822ff3537eac06f453963e412f.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000003_7db414d3c060c2ade9b68f739bdfbb4064919afda0f9b3b42eb89af4ff3311b9.png\n",
            "Total small images removed: 5\n",
            "Updated JSON saved as: /content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images_updated.json\n",
            "Created: /content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images_updated_part_1.json\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/17_artifacts/image_000002_e2cece3be96aa05931eea2488c7312b12d82969056fd50762e3f32ae19090fd2.png with context.\n",
            "Processed and saved: /content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images_updated_part_1_processed.json\n",
            "Merged JSON file saved as: 17_qwen_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images_updated_part_1_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/17_all_nodes_with_images_updated_part_1.json\n",
            "Total duplicates removed: 0\n",
            "Total small images removed: 0\n",
            "Updated JSON saved as: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images_updated.json\n",
            "Created: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images_updated_part_1.json\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_artifacts/image_000000_7948db3976c6a732cafb76488b681386fe2f51dcb66e39b0909de8010d3b6c91.png with context.\n",
            "Processed and saved: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images_updated_part_1_processed.json\n",
            "Merged JSON file saved as: 231161_OperationsMaintenanceManual_qwen_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images_updated_part_1_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/231161_OperationsMaintenanceManual_all_nodes_with_images_updated_part_1.json\n",
            "Total duplicates removed: 0\n",
            "Total small images removed: 0\n",
            "Updated JSON saved as: /content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images_updated.json\n",
            "Created: /content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images_updated_part_1.json\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000000_76f7bf71b5ee016569038b353d497dbab4ece2118c183a487e21be8cd18ca35c.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000001_802d2cfb89433b1ecd671a0eab63ca931775693fd02067c2a773613e09ae9823.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000002_4672a53d7860cc3c713b5ad43f1d332d43ad088ecf62db53c397e78dfdd288d8.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000003_52e41a5036712be79d144d79e13590238433ac351834c9407c377bb3274941d1.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000004_6af2fda4b27a06c9e63ee68e4036be50c89e6283b7b12094b48fc9a33df1996a.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000005_1f3c256b3a35438728d04abee419cb5fabc73d9759af6968bae85369b11c1116.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000006_e592f5714804acd5929d617e46249cec74bffcf20386456c5df3f4a2fe439112.png with context.\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/PDF1_artifacts/image_000007_faf5066f8d375e048223f46044611ce8f43404b57863121139abf1496eaa1cf1.png with context.\n",
            "Processed and saved: /content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images_updated_part_1_processed.json\n",
            "Merged JSON file saved as: PDF1_qwen_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images_updated_part_1_processed.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/PDF1_all_nodes_with_images_updated_part_1.json\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000012_4e378b0bcdff603abf55140c79324c17c84888680659fa892b5b073665e92745.png\n",
            "Total duplicates removed: 1\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000014_0c658427ed11413249a5b2281f272382374e19ef709fe001bb17d5de850023b0.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000019_23e3e5081555fe0c8b2b9b241850523d7adf5f91eb7480ef246b1fd0a7d82ff3.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000010_4e378b0bcdff603abf55140c79324c17c84888680659fa892b5b073665e92745.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000017_10356d829ac86b4508798bd2c207a82096110b41b8af86796e12702e60fc1e34.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000011_d7a2eb0a1731bfe407b47b00b6a62e3b3fecdc50b373415fa08a03659f298eb4.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000009_aa6c05476c26b948c10fa3d2310ec3b50612775eee109624a4457de75b6c7e13.png\n",
            "Deleted: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000026_c6fdf213ccac1c5b0d053a50e4bcee1808c92ebbcc9f2ca1043bcf93a2dd3fc8.png\n",
            "Total small images removed: 7\n",
            "Updated JSON saved as: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_all_nodes_with_images_updated.json\n",
            "Created: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_all_nodes_with_images_updated_part_1.json\n",
            "Processing: /content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_artifacts/image_000000_a6236f308b95c7b901bbc3335a0b67ecbd878d554825f4516f764fefc3c55cc1.png with context.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files = [\"/content/drive/MyDrive/output-imagenodes/ai-in-america-oai-economic-blueprint-20250113_all_nodes_with_images.json\",\n",
        "        \"/content/drive/MyDrive/output-imagenodes/creatingsystem_all_nodes_with_images.json\"\n",
        "]\n",
        "\n",
        "\n",
        "for file in files:\n",
        "  process_json_file(file)\n",
        ""
      ],
      "metadata": {
        "id": "UkkldcJ92lGP"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "7138a35df63f47a18a069aef0c62ea4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f47ed02c21e84cb8b02a6b5439d37a9c",
              "IPY_MODEL_73c7b022daa04280abd3308bfddf4b81",
              "IPY_MODEL_f7d14b3b707d434aa334210682753204"
            ],
            "layout": "IPY_MODEL_6cf67238d90f46f9a07d0a11a5337e74"
          }
        },
        "f47ed02c21e84cb8b02a6b5439d37a9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41c2606ee65e49158970422cbf89f262",
            "placeholder": "​",
            "style": "IPY_MODEL_df433ddcc99a4b91875c681c60d2d10f",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "73c7b022daa04280abd3308bfddf4b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f7bab44c9c9416ca6be772c9c25563b",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaa6fe289a26433eab1ce9b53771d104",
            "value": 2
          }
        },
        "f7d14b3b707d434aa334210682753204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2800ec3f7a2415bb1f872204bf9c6ac",
            "placeholder": "​",
            "style": "IPY_MODEL_b1fb35a6ee7447c3844ade79eb2151cb",
            "value": " 2/2 [00:33&lt;00:00, 14.40s/it]"
          }
        },
        "6cf67238d90f46f9a07d0a11a5337e74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41c2606ee65e49158970422cbf89f262": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df433ddcc99a4b91875c681c60d2d10f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7bab44c9c9416ca6be772c9c25563b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaa6fe289a26433eab1ce9b53771d104": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b2800ec3f7a2415bb1f872204bf9c6ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b1fb35a6ee7447c3844ade79eb2151cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}